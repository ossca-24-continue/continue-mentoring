# Chat: How it works

## 챗은 어떻게 동작할까?

1. 에디터 창에서 `cmd + L` 또는 사이드바 채팅창에서 `@`로 Context를 전달한다.
1. 사이드 바에서 추가적인 Prompt를 전달한다.
1. LLM 모델은 전달받은 Context와 Prompt를 기반으로 응답을 스트리밍한다.

## FAQ

### '그게 아니고~' 식으로 코드는 안 보내고 후속 조치만 보내면 어떻게 될까?

이전 세션 컨텍스트도 일부 포함된다. 추가 Context를 제공하는 게 아니라 모델이 대화의 흐름과 맥락을 기억하고 있음.

### 받은 응답을 어떻게 적용할까?

응답에 포함된 코드는 해당 블록에 배치되며 `현재 파일에 적용`, `커서에 삽입`, `복사`를 선택할 수 있다.

### 지금까지 맥락을 무효화하고 새로운 세션을 시작하고 싶다면?

`cmd + L` 또는 사이드바 채팅창에서 `새로운 채팅`을 클릭한다.

### 채팅 모델 중에 전송된 프롬프트를 볼 수 있을까?

A. 터미널 옆에 `Output` 열기
B. 드롭다운에서 `Continue - LLM Prompts/Completions` 선택
C. 전송된 프롬프트 확인

### 개발과 무관한 내용을 요청하면? (e.g. 김치찌개 레시피 알려줘)

Continue는 매우 성실하게 알려줌중.
Copilot은 `"Sorry, I can't assist with that."` 라고 응답.

# How to customize

(작성 중)
