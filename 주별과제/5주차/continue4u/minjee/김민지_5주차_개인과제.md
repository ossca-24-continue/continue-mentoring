# 3주차 - AI Code Assistant와 Continue 주요 기능 살펴보기

## AI 코딩 어시스턴트

### 주요 AI 코딩 어시스턴트

1. Amazon CodeWhisperer

    : AWS에서 제공 / AWS 환경에서의 개발 최적화 기능 (AWS 클라우드 서비스와 깊이 통합, AWS 리소스 접근 쉬운 편) / 개인의 경우 무료

2. Codex

    : OpenAI에서 개발 / Github Copilot, TabNine 드에서 서드 파티 익스텐션으로 사용 중 / GPT3.5 기준 0.02$/1000 tokens

3. Cursor

    : VS Code 기반 편집기 / 자체 프로그램으로 실행되어 호환성 문제 최소화 가능

4. 그 외 (Tabnine, Codeium, Github Copilot, replit GhostWriter 등)

### Continue

  : 개발 환경과 통합되어 사용할 수 있는 AI 코딩 어시스턴트

- 특징

  - 오픈 소스 : 커뮤니티 참여와 지원 받기 가능

  - 모델 선택 유연성 : 연결 모델을 직접 선택할 수 있어 사용자가 자유롭게 커스터마이징 가능

  - 컨텍스트 다양성 : url, Github/Jira 이슈, 데이터베이스 테이블, 구글 검색 결과 등을 컨텍스트 데이터로 선택 가능

## Continue 설치, 설정, 주요 기능 살펴보기

### Continue 설치

- VS Code 내 Extensions 앱에서 검색 후 설치 가능

- IntelliJ에서 설정 화면 앱 > 플러그인 탭에서 검색 후 설치 가능

### Continue 설정

- 초기 제공 (Free-Trial) : Chat Model(Claude, GPT, Llama3, Codestral)에 대해 최대 50회의 Free-Trial을 제공

- 모델 API Key 설정 사용 : Extension에서 add 버튼 또는 Config.json 파일을 수정해 모델별 API Key 등록 후 사용 가능

- 로컬 모델 (Ollama) 사용 : Ollama 공식 홈페이지 다운로드 -> config.json에서 models 부분 수정 후 사용 가능

### Continue 주요 기능

#### 1. Chat

: IDE 내에서 개발자들이 AI와 자연스러운 대화를 통해 문제 해결을 할 수 있도록 함

- 추천 작업 : 코드 이해 또는 반복 & 검색 엔진 쿼리 대체

- 주요 작업

  a. 코드 하이라이팅 : 코드 드래그 + `ctrl/cmd + L` 단축어를 통해 chatbox에 코드를 추가하고 질문

  b. 레퍼런스 : `@`를 이용해 코드베이스, 문서, IDE, 혹은 서드파티 정보 컨텍스트에 포함

- 지원 모델

  - open-weight model(모든 내용을 공개하진 않음), open source model (모델 관련 대부분 내용 공개, 공유) 모두 지원

- 모델 종류 : Claude SOnnet 3.5(Anthropic), Llama 3.1 405B, GPT-4o, Gemini 1.5 Pro

  (로컬 환경에서는 컴퓨터의 실행 가능 모델에 따라 Llama 3.1 8B 또는 DeepSeek Coder 2 16B를 추천함)

#### 2. Autocomplete

: 코드 작성 중 실시간 커서 이후 부분에 들어올 수 있는 내용 추천

- Autocomplete 관련 주요 전략

  - Timing : Too many request를 줄이는 전략

    1. debounce : 연속된 입력 이벤트를 하나로 처리하는 전략

    2. caching : 경량 DB인 sqlite3에 autocomplete 결과를 캐싱하는 전략

  - Filtering : 불완전한 LLM 응답을 보완하는 전략 

#### 3. Edit

: (코드 드래그) + `ctrl/cmd + I` 단축어를 통해 현재 파일을 벗어나지 않고 코드 간편 수정 가능

- 사용 사례 : 주석 추가 / 단위 테스트 생성 / 함수 리팩토링 등 => 작은 수정이나 빠른 변경에 적합

#### 4. Actions

: 채팅창에서 `/` 기호로 시작하는 단축어(슬래시 명령어)를 통해 미리 지정된 Action 수행 가능

- 기본 제공 슬래시 명령어 : `/edit`, `/comment`, `/share`, `/cmd`, `/commit`, `/http`, `/issue`, `/so`, `/onboard` 등

- 장점 : 자주 사용하는 작업에 빠른 액세스 가능 / .prompt 파일을 사용한 커스터마이징 가능

# 4주차 - 백그라운드 지식 (LLM, 프롬프팅, RAG, benchmark, Model Provider) 익히기

## Continue에서 사용하는 모델 유형

#### 1. Autocomplete Model

: FIM 기법으로 훈련된 특수한 언어 모델 사용 / 작은 규모의 모델로도 우수한 성능 발휘 가능

- Continue에서의 활용 : Autocomplete 기능에 사용

- 추천 모델 : Codestral / 로컬 사용 시 Ollama Starcoder2-3B 모델

#### 2. Chat Model

: 대화 형식에 응답하도록 훈련된 언어 모델 사용

- Continue에서의 활용 : Chat, Edit, Action 기능에 사용

- 추천 모델 : Claude 3.5 Sonnet / 그 외 - GPT 4o, Gemini 1.5 Pro, Llama3.1 405B 

#### 3. Embeddings Model

: 텍스트를 벡터값으로 변환해 텍스트 간의 유사도를 비교해주는 모델

- Continue에서의 활용 : 인덱싱 과정 중 임베딩 생성 -> @Codebase 기능에서 활용 (코드베이스 전체에 대한 유사성 검색)

- 추천 모델 : Voyage-code-2 / 로컬 사용 시 Ollama와 함께 nomic-embed-text 추천

#### 4. Reranking Model

: 검색 결과를 다시 정렬하는데 사용, 문서가 질문에 답변하는데 얼마나 유용한지 측정

- Continue에서의 활용 : @codebase 기능에서 리랭킹 모델 사용, 벡터 검색 후 가장 관련성 높은 코드 스니펫 선택하는데 사용

- 추천 모델 : Voyage AI의 rerank-1 / Cohere에서 제공하는 리랭킹 모델 추천


## Continue의 Model Provider

: AI 모델을 제공하는 서비스나 플랫폼 / 모델과 연동할 플랫폼을 선택해야 함

> Continue에서는 free tiral 제외 총 28개의 Model Provider를 제공 중

1. AI 모델 제공 및 개발 플랫폼

    : 자사 개발 모델에 대한 API를 제공하는 서비스

    - Mistral, Anthropic, Deepseek, Gemini, Ollama, OpenAI

2. 클라우드 AI 서비스

    : 대규모 클라우드 제공 업체가 제공하는 AI 및 머신러닝 서비스 / 모델 훈련, 배포, 관리를 위한 종합 플랫폼 제공 서비스

    - 장점 : 물리적인 인프라 구축 필요 없이 사용한만큼만 지불하는 구조 => 초기 투자 비용 절감 가능

    - 단점 : 데이터가 제3자와 공유될 수 있는 위험성 존재 / 사용량 증가 시 비용이 더 들 수 있음

    - Azure OpenAI, Amazon Bedrock

3. AI 모델 배포 및 서버리스 플랫폼

    : AI 모델을 효율적으로 배포하고 관리하기 위한 도구와 서비스

    - Cloudflare Workers AI, HuggingFace Inference Endpoints, DeepInfra, Together, vLLM

4. 로컬 AI 실행 도구

    : 개인 컴퓨터, 로컬 서버에서 AI 모델을 실행할 수 있게 해주는 소프트웨어

    - 데이터 프라이버시, 오프라인 사용을 중시할 경우 유용함

    - Ollama, LlamaCpp, Llamafile, LM Studio, TextGenWebUI

5. AI 워크플로우 및 통합 도구

    : AI 모델을 기존 시스템이나 워크 플로우에 쉽게 통합할 수 있게 해주는 도구

    - AI 기술의 접근성을 높이고 활용도를 증가시킴

    - Flowise, Kindo, Msty, OpenRouter

6. 특정 분야, 기술 특화 AI 서비스

    : 멀티 모달 AI, 고성능 추론, 하드웨어 최적화 등 특정 니즈 충족 솔루션 제공

    - Gemini, Groq, IPEX-LLM, ReplicateLLM

## LLM과 completion options, 프롬프팅, LLM benchmark

### LLM (대규모 언어 모델)

: 대용량의 데이터셋(매개변수)를 통해 인간의 언어를 이해하고 생성할 수 있는 대규모 딥러닝 언어모델

#### CodeLLM

: 일반적인 LLM의 개념을 코드 생성과 자동완성에 특화한 모델

### LLM Completion Options

: 언어모델이 텍스트를 생성하는 방식을 조정하는 설정

- 출력되는 텍스트의 길이, 다양성, 일관성 등에 영향을 미침

- 각 모델마다 지원하는 Option들도 약간씩 상이하며, 동일값을 주더라도 응답 변화 편차 존재 가능

#### Continue에서 수정할 수 있는 LLM Completion Option 옵션

- `stream` : LLM 응답을 streaming으로 받을지 선택하는 옵션 / 스트리밍으로 받을 경우 응답을 점진적으로 받을 수 있음

- `temperature` : 모델이 생성하는 응답의 창의성이나 랜덤성

    - 높은 값 : 창의적, 랜덤

    - 낮은 값 : 일관적 & 예측 가능

- `topP` : LLM에서 생성하는 단어를 선택하는 과정에서 확률 분포 상위 P%의 단어들만 선택해 응답을 생성하는 방식

    - 높은 값 : 다양한 단어 선택

    - 낮은 값 : 확률이 높은 단어들만 선택

- `topK` : LLM에서 응답을 생성할 때 고려할 후보 단어들의 개수 제한 옵션

    - 높은 값 : 더 창의적, 다양한 단어 선택

    - 낮은 값 : 예측 가능하고 고정된 표현 사용 가능성 높음

- `maxTokens` : 모델이 생성할 수 있는 최대 토큰 수

    - 역할 : 모델이나 하나의 프롬프트에 대해 응답할 때 생성할 텍스트의 길이 제한

- 그외 : presencePenalty, frequencePenalty, mirostat, stop, numThreads, keepAlive

### 프롬프팅

: 인공지능 모델, 특히 자연어 처리와 관련된 모델에 입력으로 제공하는 텍스트 (모델에게 특정 작업을 수행하도록 지시하는 문구나 질문)

#### 효과적인 프롬프트 엔지니어링

> 사용자는 프롬프트 디자인의 다양한 전략과 기법을 통해 효과적으로 질문함으로써, LLM의 성능을 최적화하여 더 나은 응답 결과를 도출할 수 있음

- 질문하기 전 생각 구조화 : 생각의 연결고리 (Chain-of-Thought, CoT)를 통해 대답 유도

- 프롬프트에게 페르소나 부여 : 역할, 맥락, 배경을 부여하고 답변 난이도를 결정하는 문제 상황을 지정

- 명확하고 구체적으로 (범위를 좁혀서, 출력 포맷 명시, 추출 방법 명시)

- 영어로 번역해서 질문하기 : 영어 질문 시 답변 퀄리티가 더 좋기에 영어 질문 -> 한국어 번역

- 보상 제시하기 : 질문에 응답할 때 동기를 부여하기 위한 보상 제시

## RAG (검색 증강 생성)

: LLM이 자체 지식 기반 외에도 외부 데이터베이스나 검색 엔진을 활용해 더 정확하고 최신의 정보를 제공하는 방법

- LLM을 직접 학습시키는 것이 아닌 외부 데이터를 검색해 참조하는 모델 (실시간 필요 정보 검색 후 해당 데이터 바탕 텍스트 생성)

- RAG가 중요한 이유

    - 신뢰할 수 있는 정보 소스 활용 : 검증된 외부 자료를 사용해 응답 신뢰성 높임

    - 사용자 신뢰도 향상 : 정확하고 최신의 정보를 제공함으로써 사용자들의 시스템 신뢰도를 높임

### RAG 작동 방식

1. Chunking : 대규모의 문서를 여러개의 작은 chunk로 나누는 과정

    - 중요한 정보 손실을 최소화하면서 각 chunk가 독립적으로 처리될 수 있도록 설계

    - chunk 구분 : 문서의 논리적 다누이 또는 문단 기준

    - chunking 방법 : Fixed Size Chinking (문자 길이 기준), Context-Aware chunking(문맥 기준, 긴 문단 발생 위험 존재), Recursive chunking (Fixed size와 Context-Aware을 혼합 사용)

2. Document Embeding : 문서 내의 텍스트를 고차원 공간의 벡터로 변환해 문서 간의 유사도를 계산

3. Retrieval : 입력 쿼리에 맞는 관련 문서 또는 청크 검색

    - Retrieval 방식 : Dense 방식(회소 백터로 변환), Sparese 방식 (BERT와 같은 신경망 모델 사용해 변환)

4. Reranking : Retrieval된 문서 중 가장 관련성 높은 것만 선택

    - 단순 임베딩 유사도 계산 이상의 다양한 요소를 고려해 실행된다

    - reranking을 통해 필요한 것만 넣어 정교한 답변을 생성할 수 있도록 유도 가능

### LLM 벤치마크

: LLM을 다양한 작업에서 성능을 평가하기 위해 사용하는 표준화된 테스트 모음

- LLM을 평가하기 위한 방법으로는 크게 `사람 평가`와 `벤치마크를 이용한 기계적 평가`가 존재한다.

    - 대표적인 사람 평가 : https://lmarena.ai/

#### 주로 사용되는 평가지표

- pass@k : k번 내에 맞추는 횟수

- F1 점수 : 정밀도와 재현율의 조화 평균으로 불균형한 데이터셋에서 모델 성능 평가

#### 대표적인 LLM 벤치마크

- **HumanEval** : 코드 생성 능력 평가 벤치마크 / 평가지표로 pass@1을 주로 사용

- **MBPP** : 실제 코딩 문제 해결 능력 평가 벤치마크 / 리스트 조작부터 재귀와 같은 응용 문제까지 다양하게 구성 / 평가지표로 pass@1을 주로 사용

- **EvalPlus** : HumanEval과 MBPP 확장 벤치마크

- **CodeXGLUE** : 코드 생성, 요약, 검색 등 코드 관련 작업을 포괄적으로 평가하는 벤치마크

- **CRUXEval** : 코드 추론, 이해 및 실행 능력을 평가하는 벤치마크 / 입력 예측 (CRUXEval-I)와 평가 예측 (CRUXEval-O) 작업으로 구성

#### 한국어 이해 능력 평가 관련 벤치마크

- **Ko-IFEval** : 정보 추출 모델의 능력을 평가하기 위한 벤치마크

- **Ko-GSMBk** : 수학 문제 해결 능력 평가 벤치마크

- **KorNAT-SVA** : 한국어 문장의 구조적 이해를 평가하는 벤치마크

### Continue의 기능별 LLM 모델 선택하기

#### 1. Chat 모델

- 선택 기준 : 코딩 성능 + 한국어 이해 능력

    - 코드 작성 특화 대화에 맞게 '논리구조 파악 능력'과 '문제 해결 능력'에 초점을 둔 한국어 이해능력 벤치마크를 볼 것을 추천

#### 2. Autocomplete 모델

- 선택 기준 : FIM 모델 지원 여부 + 코딩 성능 + 응답 속도(Latency)와 모델 크기 + 정확도 + 맥락 이해도 (맥락 길이)

    - FIM 기능 관련 벤치마크로는 SAFIM이 존재하나, 최신 코드 특화 모델에 대한 업데이트가 되지 않은 상황

    - Continue에서 지원하는 모델을 확인한 뒤 해당 모델들의 벤치마크 성능 결과를 각 벤치마크별로 확인하거나 각 모델의 공식 사이트에서 내놓은 결과를 바탕으로 판단 가능

- Autocomplete 모델로는 성능이 전반적으로 우수한 대형 모델이 아닌 FIM 기능을 지원하는 작은 크기의 코드 특화 모델을 사용한다

    - 대형 모델의 경우 일반적인 자연어 처리 작업에 강점을 갖고 있으나, 코드 자동 완성이나 FIM 작업을 위해 훈련된 모델은 아니기 때문에 구체적 문맥 이해와 최적화된 프롬프트 형식에서 약점이 존재한다

    - 대형 모델의 경우 파라미터 수가 매우 많고 복잡하기에 응답 시간이 느리며, 이는 실시간 빠른 응답이 중요한 자동 완성 작업에서는 적합하지 않다

    - Continue 공식 문서에 따르면 최신 자동완성 모델들은 대부분 10B 파라미터 이하로, 파라미터가 초과한다고 하더라도 성능이 크게 개선되진 않는다

- 선택 가이드

    - 클라우드 서비스를 이용할 경우 CodeStral 사용 추천
    - 로컬 환경에서 이용할 경우 CodeLlama 사용 추천
    - FIM, 모델 크기 등의 기준을 갖고 코드 자동완성 특화 LLM의 최신 소식 확인 후 적용해볼 것을 추천

#### Embedding 모델

- Code 임베팅 모델에서 고려해야 할 사항

    - 구문적 특성 : 프로그래밍 언어의 문법과 구조 고려
    
    - Semantic 정보 (의미 검색 / 시맨틱 검색) : 구문 내의 단어 의미와 특성을 잘 파악해야 함

    - 실행 컨텍스트 : 코드의 실행 흐름과 의존성 관계 반영

- Continue에서의 임베딩처리 : 인덱싱하는 동안 처리된 이후, DB에 저장, @Codebase를 사용해 코드 베이스에 대한 유사도 검색을 수행

- 선택 가이드

    - 모델 크기별
    
         - 100MB 미만 : Tranformers.js의 all-MiniLM-L6-v2

         - 100MB ~ 1GB : Text Embeddings Inference 또는 Ollama의 nomic-embed-text

         - 1GB 이상 : Upstage solar-embedding-1-large-query

    - 리소스 제약 환경에서는 Transfomers.js 추천

    - 온프레미스 요구 환경에서는 Ollama 또는 Text Embeddings Inference 추천

    - 클라우드 / API 기반 환경에서는 OpenAI, Gemini 추천하나 비용 부담을 고려해야 한다

#### Rerank 모델

- Continue에서의 리랭크 처리 : Context Provider 기능, 특히 @codebase나 @folder 기능에 사용

- Rerank 모델 고려 사항 : 문맥 파악 능력 (long context에 대한 이해), 속도, 코딩 능력, 한국어 능력

- 선택 가이드

    - Continue 추천 모델 : voyage AI의 rerank-1 (빠른 속도 & 다국어 지원 & 임베딩 retriever와 조합 시 코드 문서 찾는 품질 우수)

    - 한국어 처리 능력 중점 : bge reranker (한국어 처리 능력 우수 & 무료 & 가벼움)

