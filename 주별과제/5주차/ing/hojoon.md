# Contribution Idea

## .gitignore 과 같은 .continueIgnore

### 기능

- `.gitignore`와 같은 방식으로 `.continueIgnore` 파일을 생성하여 특정 파일이나 디렉토리를 제외할 수 있도록 하는 기능을 추가한다.
- `.continueIgnore` 파일에 특정 파일이나 디렉토리를 추가하면 해당하는 것들은 vectorDB에 저장하지 않는다.

### 필요성

- 사용자가 가지고 있는 파일 중에 굳이 저장할 필요가 없는 것들이 있을 수 있기 때문에 메모리 절약 및 불필요한 Retrieve를 줄이기 위해 필요하다.
- 외부 API를 사용할 때 Codebase에서 외부로 유출되는 것을 방지할 수 있다.

---

## 언어 설정

### 기능

- 사용자가 원하는 언어 또는 사용자가 사용하는 OS 상에 설정된 언어를 기반으로 Chat의 답변을 생성하는 기능

### 필요성

- 한국어 사용자로서 답변이 항상 영어로 생성되는 것은 불편합

### 구현 방법

- 프롬프트를 통한 해결 가능
- 사용자가 가지고 있는 메타데이터를 프롬프트에 넣거나, 사용자가 질문한 언어에 맞게 답변을 생성할 수 있도록 함

---

## 코드 스타일 

### 기능

- AutoComplete 기능에서 사용자가 미리 설정 해놓은 코드 스타일로 코드를 생성할 수 있도록 하는 기능
- (camelCase, snake_case, PascalCase 등) , (K&R, BSD, GNU 등), (들여쓰기 규칙)

---
# 3주차

## AI 코딩 어시스턴트 도구 조사와 비교 분석

### 목차
1. **서론**  
   - AI 코딩 어시스턴트의 중요성
2. **AI 코딩 어시스턴트 도구 조사**  
   - 다양한 도구 분석 (Amazon CodeWhisperer, Codex 등)
3. **Continue 도구의 특징**  
   - 기능 및 차별점
4. **결론**  
   - 도구 선택 가이드라인

### 요약
AI 코딩 어시스턴트 도입은 생산성 향상, 코드 품질 개선, 오류 감소 등 다양한 이점을 제공한다. 각 도구의 특성과 장단점을 비교 분석하며, 특히 Continue의 오픈소스 특성을 강조한다.

---

## Continue 설치, 설정 및 주요 기능 개요

### 설치 및 설정
1. **VSCode/IntelliJ 설치**: 확장 프로그램을 통해 간편하게 설치 가능.
2. **API Key 등록**: OpenAI, Anthropic 등에서 API 키를 설정.
3. **로컬 모델 구성**: Ollama 사용으로 로컬에서 실행 가능.

### 주요 기능
- **Chat**: 실시간 대화를 통한 코드 설명 및 문제 해결 지원.
- **Autocomplete**: 코드 작성 시 인라인 코드 제안 제공.
- **Edit 및 Actions**: 빠른 코드 수정 및 작업 수행 지원.

---

## Continue Chat과 Autocomplete 기능 상세 분석

1. **Chat**  
   - 사용법, 모델 설정, 컨텍스트 선택
2. **Autocomplete**  
   - 사용법, 모델 설정, 컨텍스트 선택

### Chat 기능
- **사용법**: IDE 내에서 자연어 기반 대화 지원.
- **모델 설정**: 다양한 AI 모델 선택 가능.
- **컨텍스트 선택**: 작업 중인 파일이나 폴더와 같은 컨텍스트를 명확하게 설정.

### Autocomplete 기능
- **사용법**: 코드 작성 시 실시간으로 자동 제안 제공.
- **모델 추천**: Codestral 모델 권장.
- **컨텍스트 선택**: 커서 위치를 기반으로 맥락을 분석해 적절한 제안을 제공.

---

## Continue Edit와 Actions 기능 상세 분석

### 사용법

#### Edit
- **개요**: 인라인 코드 수정을 통해 간편하게 변경 가능.
- **사용법**: 코드 블록을 선택 후 cmd/ctrl + i를 눌러 활성화.
- **장점**: 작은 수정과 빠른 변경에 최적화.

#### Actions
- **개요**: 자주 사용하는 작업을 위한 단축 액션 제공.
- **사용법**: `/` 입력 후 명령어 입력으로 작업 수행.
- **장점**: 커스터마이즈 가능하며, 반복 작업을 간소화.

### Tip
- **Edit**는 파일 내 즉각적인 수정에 적합하며, **Actions**는 반복 작업을 간소화하는 데 유용.

---

# 4주차

## Continue 모델 유형과 연동 방식 조사

### Continue에서 사용하는 모델 유형 및 연동 방식


### 모델 유형 조사
Continue는 다음과 같은 모델을 사용:

1. **Autocomplete Model**: 코드 작성 시 실시간 제안 제공.
2. **Chat Model**: 자연어 대화를 통해 코드 문제 해결.
3. **Embeddings Model**: 텍스트를 벡터로 변환해 유사성을 비교.
4. **Reranking Model**: 검색 결과를 평가하고 재정렬.

### 모델 연동 방식 조사
Continue는 여러 AI 모델 제공자를 통해 모델을 연동함:

1. **AI 모델 플랫폼**: Anthropic, OpenAI, Mistral.
2. **클라우드 서비스**: Azure, Amazon Bedrock.
3. **로컬 실행 도구**: Ollama, LlamaCpp.
4. **AI 워크플로우 도구**: Flowise.
5. **특화된 AI 서비스**: Gemini, Groq.

---

## LLM Completion 옵션 설정과 효과적인 프롬프팅

### LLM Completion 옵션
Continue 설정 파일에서 `temperature`, `topP`, `maxTokens` 등 옵션을 설정할 수 있으며, 이러한 옵션은 결과물의 다양성과 창의성에 영향을 미친다.

### 프롬프트 커스터마이징
- **Context Provider**: LLM에 제공할 정보를 사용자 정의 가능.
- **Completion 옵션**: 다양한 옵션을 설정해 더 나은 응답을 유도 가능.

### 프롬프트 엔지니어링
효과적인 프롬프트 설계를 통해 LLM의 성능을 극대화할 수 있으며, 전략적 설계를 통해 더 정확하고 유용한 결과를 얻을 수 있다.

---

## RAG 개요와 Continue에서의 활용

### RAG 개요
RAG (Retrieval-Augmented Generation)는 LLM이 외부 데이터베이스를 활용해 정보를 보강하는 방법으로, 정확한 응답을 제공한다.

### RAG의 장점
- 최신 정보에 접근할 수 있어 신뢰도 높은 답변 생성 가능.
- 다양한 활용 분야에서 강력한 성능 발휘 (예: 고객 지원, 법률 정보 제공).

### 활용 예시
- **고객 지원 챗봇**
- **법률 및 의료 정보 제공**
- **연구 보조 도구**

### 작동 방식
RAG는 문서 청크화, 임베딩, 검색, 그리고 응답 생성의 단계를 거쳐 작동한다.

---

## LLM 개요와 벤치마크, 선택 가이드

### LLM (Large Language Model)
LLM은 대규모 데이터를 학습해 자연어를 이해하고 생성하는 모델이다.

#### 주요 주제
- **양자화(Quantization)**: 모델 크기를 줄이는 방법으로 INT4와 INT8의 차이를 설명.
- **벤치마크**: HumanEval, MBPP, CodeXGLUE 등의 성능 평가 지표.

### LLM 벤치마크
다양한 벤치마크를 통해 LLM의 성능을 측정할 수 있으며, 이는 모델의 효율성을 평가하는 중요한 기준이 된다.

### LLM 선택 가이드
- **공통 기준**: 비용, 양자화 수준, 코딩 성능 등을 고려해 최적의 모델을 선택.


---
