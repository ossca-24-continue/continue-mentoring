** Continue **
개요
Continue는 개발 환경과 통합되어 코딩 작업을 지원하는 오픈소스 도구
AI 모델을 커스터마이징할 수 있는 점이 특징임. 코드 자동 완성, 대화형 코드 설명, 자연어 기반 코드 수정 등의 기능을 제공함.
(지원 IDE에는 VS Code, IntelliJ가 있음)

** 차별화된 특징 **
1) 개발 데이터 수집 : 자동으로 .continue/dev_data 디렉토리에 데이터를 수집해 팀의 AI 어시스턴트를 지속적으로 개선
2) 오픈 소스 : 커뮤니티 참여와 지원을 받을 수 있고 무료로 사용가능한 오픈 소스
3) 모델 선택 유연성 : 다양한 AI 모델을 선택하여 사용자의 선호와 사용성에 따라 활용 가능
4) 다양한 컨텍스트 사용 : 코드베이스뿐 아니라 URL, GitHub/Jira 이슈, 데이터베이스 등을 컨텍스트로 활용할 수 있는 기능

** Continue 기능 요약 **
1. Chat
- 사용자는 AI와의 대화를 통해 코드 관련 문제를 해결하거나 설명을 요청.
특징 :
1) 코드에 대한 질문을 하고, 수정 또는 분석을 요청 가능.
2) 프로젝트 파일이나 문서를 참조하여 컨텍스트 기반 답변 제공.
3) 코드 하이라이팅, 오류 찾기, 개선 제안, 코드 작동 방식 설명 등이 가능.
4) 대화에서 생성된 코드를 현재 파일에 삽입하거나 적용 가능.

2. Autocomplete
- 사용자가 코드 작성 시, AI가 실시간으로 코드를 예측하고 완성 제안.
특징 : 
1) 빠르고 효율적인 코드 작성 가능.
2) 반복적인 코드 작성을 줄여주며, 문맥에 맞는 코드 제안.
3) 함수, 변수명, 코드 구조 등을 자동으로 완성.
4) 다양한 프로그래밍 언어에서 사용 가능하며, 개발자의 생산성을 높이는 데 도움.

3. Edit
- 코드 편집을 위한 명령을 AI에게 내리면, 해당 코드가 자동으로 수정됩니다.
특징 :
1) 특정 코드의 리팩토링, 성능 개선, 오류 수정 등을 요청 가능.
2) 불필요한 코드 제거, 가독성 향상 등 코드 품질 개선 작업을 쉽게 수행.
3) AI에게 스타일 변경이나 주석 추가를 요청하여 코드의 일관성을 유지 가능.
4) 명령어를 통해 부분적인 코드 수정도 가능하며, 프로젝트 전반에 걸쳐 적용 가능.

4. Action
- 다양한 작업(빌드, 테스트 실행, 코드 검토 등)을 자동으로 실행할 수 있는 기능.
특징 :
1) 빌드 및 테스트 자동화, 코드 분석, 성능 측정 등의 작업을 AI가 처리.
2) 복잡한 작업을 명령 한 줄로 실행 가능.
3) 코드 실행 후 결과를 분석하고, 그에 따른 피드백을 제공받아 신속한 수정 가능.
4) 다양한 IDE 및 터미널 명령어와 연동되어 효율적으로 작업 수행 가능.

** Continue 모델 유형 **
1. Chat
 대화 형식으로 응답하도록 학습된 LLM으로, 복잡한 질문에 답변하고 코드를 생성하는 데 사용됨. 일반적으로 4백억 개 이상의 매개변수를 가진 모델이 필요함.
용도 : Chat, Edit, Action 기능에 활용.

2. Autocomplete
 자동 완성 모델은 중간 채우기(FIM) 기법으로 훈련된 언어 모델로, 코드나 텍스트의 앞뒤 내용을 바탕으로 중간에 들어갈 내용을 예측함. 상대적으로 작은 규모(3B 매개변수)로도 우수한 성능을 발휘할 수 있음.
- 용도 : 코드 작성 시 실시간으로 인라인 제안을 제공함.
- 예시 : Google 검색창에서 입력 중 제안되는 문구, 코드 편집기에서의 함수 및 변수명 추천.

3. Embeddings
 텍스트를 벡터값으로 변환하여 텍스트 간의 유사도를 비교할 수 있게 해주는 모델임. LLM보다 작은 모델로, 매우 빠르고 저렴하게 동작함.
- 용도 : 코드베이스 전체에 대한 유사성 검색에 사용되며, 워크스페이스에서 가장 관련성 있는 컨텍스트를 자동으로 가져옴.
- 예시 : Spotify에서 사용자의 취향에 맞는 곡 추천.

4. Rerank
 검색 결과를 다시 정렬하는 데 사용되며, 관련성을 평가하여 가장 적합한 결과를 상위에 배치함. 텍스트의 관련성 점수를 반환함.
- 용도: @codebase 기능에서 벡터 검색 후 가장 관련 높은 코드 스니펫을 선택하는 데 필요함.

Continue 모델 연동 방법
Continue에서 Model Provider는 AI 모델을 제공하는 서비스나 플랫폼을 의미함. 사용자는 Provider를 설정하여 모델과 연동할 플랫폼을 선택하고, 각 Provider가 제공하는 AI 모델을 선택할 수 있음.

** Tip)알아둬야 하는 LLM 개념 **
- LLM : 대용량의 데이터 셋(매개변수)를 통해 인간의 언어를 이해하고 생성할 수 있는 대규모 딥러닝 언어 모델
- 양자화 : 모델의 파라미터를 더 적은 비트로 표현하여 모델 크기를 줄이고 추론 속도를 향상시키는 기법
- LLM 벤치마크 :  LLM을 다양한 작업에서 성능을 평가하기 위해 사용하는 표준화된 테스트 모음

** LLM 벤치마크 **
1. HumanEval : 자연어 프롬프트와 테스트 케이스를 통해 코드 생성 능력을 평가. 주로 pass@1 지표를 사용하여 정확성을 측정. 다양한 언어 지원을 통해 코드 작성 능력 평가.
2. MBPP : 974개의 Python 프로그래밍 문제로 구성되어 실제 문제 해결 능력을 평가. 간단한 리스트 조작부터 재귀 문제까지 다양성 제공. 주로 pass@1 지표를 사용하여 평가.
3. EvalPlus : HumanEval과 MBPP를 확장한 벤치마크로 더 많은 테스트 케이스 포함. 복잡한 상황에서 성능을 정밀하게 평가. 기존 문제와 유사한 경우가 많아 차별성 부족 평가.
4. CodeXGLUE : 코드 생성, 요약, 검색 등 다양한 작업을 평가하는 포괄적인 벤치마크 세트. 여러 프로그래밍 언어 지원을 통해 다각적인 성능 평가. 태스크의 다양성으로 결과 해석 복잡성 증가 평가.
5. CRUXEval : 코드 추론과 실행 능력을 평가하는 벤치마크. 800개의 함수와 입력-출력 쌍을 사용하여 정확성 측정. 입력 및 출력 예측 작업을 통해 평가.
6. APPS : 고급 프로그래밍 문제를 포함하여 복잡한 문제 해결 능력을 평가. 다양한 난이도의 문제를 제공하여 실제 작업 대응 능력 확인. 문제 수가 적어 평가 일관성 부족 평가.

** 중요 개념) RAG **
RAG 개념은 정보 검색과 생성 모델을 결합하여 더 정확하고 유용한 정보를 제공하는 방법임. 
이 방식에서는 외부 데이터베이스에서 관련 정보를 검색한 후, 해당 정보를 바탕으로 자연어 응답을 생성함으로써 응답의 품질을 향상시킴. 
RAG는 특히 LLM이 제한된 지식 범위를 가질 때 유용하며, 최신 정보나 구체적인 데이터에 접근하여 보다 정확한 답변을 생성할 수 있도록 지원함.






